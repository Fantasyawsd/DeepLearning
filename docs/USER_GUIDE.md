# æ·±åº¦å­¦ä¹ æ¨¡å‹æ¡†æ¶ - ç”¨æˆ·æŒ‡å—

## ç›®å½•
1. [ä»‹ç»](#ä»‹ç»)
2. [å¼€å§‹ä½¿ç”¨](#å¼€å§‹ä½¿ç”¨)
3. [é¡¹ç›®ç»“æ„](#é¡¹ç›®ç»“æ„)
4. [æ¨¡å‹ä½¿ç”¨](#æ¨¡å‹ä½¿ç”¨)
5. [è®­ç»ƒæ¨¡å‹](#è®­ç»ƒæ¨¡å‹)
6. [é«˜çº§ç”¨æ³•](#é«˜çº§ç”¨æ³•)
7. [æ•…éšœæ’é™¤](#æ•…éšœæ’é™¤)

## ä»‹ç»

æ¬¢è¿ä½¿ç”¨æ·±åº¦å­¦ä¹ æ¨¡å‹æ¡†æ¶ï¼æœ¬é¡¹ç›®æä¾›äº†æŒ‰é¢†åŸŸåˆ†ç±»çš„å‰æ²¿æ·±åº¦å­¦ä¹ æ¨¡å‹çš„PyTorchå®ç°ï¼š

### ğŸ¯ è®¡ç®—æœºè§†è§‰æ¨¡å‹
- **MAE (æ©ç è‡ªç¼–ç å™¨)** - è‡ªç›‘ç£è§†è§‰è¡¨ç¤ºå­¦ä¹ 
- **ViT (è§†è§‰Transformer)** - åŸºäºæ³¨æ„åŠ›æœºåˆ¶çš„å›¾åƒåˆ†ç±»
- **LeNet** - ç»å…¸CNNæ¶æ„
- **ResNet** - æ®‹å·®ç½‘ç»œç³»åˆ—
- **YOLOv1** - å®æ—¶ç›®æ ‡æ£€æµ‹

### ğŸ¯ è‡ªç„¶è¯­è¨€å¤„ç†æ¨¡å‹  
- **GPT** - ç”Ÿæˆå¼é¢„è®­ç»ƒTransformer

æ‰€æœ‰æ¨¡å‹éƒ½æ„å»ºåœ¨ç»Ÿä¸€çš„æ¡†æ¶ä¸Šï¼Œå…·æœ‰ä¸€è‡´çš„APIï¼Œä¾¿äºè¯•éªŒä¸åŒçš„æ¶æ„ã€‚

## å¼€å§‹ä½¿ç”¨

### ç¯å¢ƒè¦æ±‚

- Python 3.8 æˆ–æ›´é«˜ç‰ˆæœ¬
- PyTorch 1.12.0 æˆ–æ›´é«˜ç‰ˆæœ¬
- CUDAå…¼å®¹çš„GPUï¼ˆæ¨èç”¨äºè®­ç»ƒï¼‰

### å®‰è£…

1. **å…‹éš†ä»“åº“ï¼š**
   ```bash
   git clone https://github.com/Fantasyawsd/DeepLearning.git
   cd DeepLearning
   ```

2. **å®‰è£…ä¾èµ–ï¼š**
   ```bash
   pip install -r requirements.txt
   ```

3. **ä»¥å¼€å‘æ¨¡å¼å®‰è£…åŒ…ï¼š**
   ```bash
   pip install -e .
   ```

4. **éªŒè¯å®‰è£…ï¼š**
   ```bash
   python -c "from models import MAE, ViT, LeNet, ResNet, GPT; print('å®‰è£…æˆåŠŸï¼')"
   ```

### å¿«é€Ÿå¼€å§‹

è¿è¡Œç¤ºä¾‹è„šæœ¬éªŒè¯ä¸€åˆ‡æ­£å¸¸ï¼š

```bash
# æµ‹è¯•MAE
python examples/mae_example.py
```

## é¡¹ç›®ç»“æ„

```
DeepLearning/
â”œâ”€â”€ computer_vision/            # è®¡ç®—æœºè§†è§‰
â”‚   â”œâ”€â”€ image_classification/   # å›¾åƒåˆ†ç±»
â”‚   â”‚   â”œâ”€â”€ cnn/               # CNNç³»åˆ—
â”‚   â”‚   â”‚   â”œâ”€â”€ lenet/         # LeNet-5å®ç°
â”‚   â”‚   â”‚   â””â”€â”€ resnet/        # ResNetç³»åˆ—
â”‚   â”‚   â””â”€â”€ transformer/       # Transformerç³»åˆ—
â”‚   â”‚       â”œâ”€â”€ mae/           # æ©ç è‡ªç¼–ç å™¨
â”‚   â”‚       â””â”€â”€ vit/           # è§†è§‰Transformer
â”‚   â””â”€â”€ object_detection/      # ç›®æ ‡æ£€æµ‹
â”‚       â””â”€â”€ yolo_series/       # YOLOç³»åˆ—
â”‚           â””â”€â”€ yolov1/        # YOLOv1å®ç°
â”œâ”€â”€ nlp/                       # è‡ªç„¶è¯­è¨€å¤„ç†
â”‚   â””â”€â”€ language_models/       # è¯­è¨€æ¨¡å‹
â”‚       â””â”€â”€ gpt_series/        # GPTç³»åˆ—
â”‚           â””â”€â”€ gpt/           # GPT-1å®ç°
â”œâ”€â”€ shared/                    # å…±äº«ç»„ä»¶
â”‚   â””â”€â”€ base_model.py         # åŸºç¡€æ¨¡å‹ç±»
â”œâ”€â”€ utils/                     # å·¥å…·æ¨¡å—
â”œâ”€â”€ configs/                   # é…ç½®æ–‡ä»¶
â”œâ”€â”€ examples/                  # ä½¿ç”¨ç¤ºä¾‹
â”œâ”€â”€ docs/                      # æ–‡æ¡£
â””â”€â”€ models.py                  # æ¨¡å‹å¯¼å…¥æ¥å£
```

æ¯ä¸ªæ¨¡å‹ç›®å½•éƒ½åŒ…å«ï¼š
- `model.py` - æ¨¡å‹å®ç°
- `train.py` - è®­ç»ƒè„šæœ¬  
- `test.py` - æµ‹è¯•è„šæœ¬
- `dataset.py` - æ•°æ®å¤„ç†
- `config.yaml` - é…ç½®æ–‡ä»¶
- `README.md` - ä½¿ç”¨è¯´æ˜

## æ¨¡å‹ä½¿ç”¨

### åŸºæœ¬ä½¿ç”¨æ¨¡å¼

æ‰€æœ‰æ¨¡å‹éƒ½éµå¾ªç›¸åŒçš„ä½¿ç”¨æ¨¡å¼ï¼š

```python
from models import MAE  # æˆ–å…¶ä»–æ¨¡å‹: ViT, LeNet, ResNet, GPT
from utils import Config

# 1. åŠ è½½é…ç½®
config = Config.from_file('configs/model_config.yaml')
# æˆ–è€…ä»¥ç¼–ç¨‹æ–¹å¼åˆ›å»ºé…ç½®
config = Config({
    'model_name': 'model_name',
    'param1': value1,
    'param2': value2,
})

# 2. åˆ›å»ºæ¨¡å‹
model = ModelName(config.to_dict())

# 3. ä½¿ç”¨æ¨¡å‹
model.eval()  # è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼
outputs = model(inputs)

# 4. è·å–æ¨¡å‹ä¿¡æ¯
model.summary()
print(f"æ¨¡å‹å‚æ•°æ•°é‡: {model.count_parameters()}")
```

### é…ç½®ç®¡ç†

æ¡†æ¶ä½¿ç”¨YAMLé…ç½®æ–‡ä»¶æ¥æ–¹ä¾¿æ¨¡å‹è‡ªå®šä¹‰ï¼š

```python
from utils import Config

# ä»æ–‡ä»¶åŠ è½½
config = Config.from_file('configs/mae_config.yaml')

# ä»¥ç¼–ç¨‹æ–¹å¼åˆ›å»º
config = Config({
    'model_name': 'mae',
    'img_size': 224,
    'patch_size': 16,
    'embed_dim': 768
})

# è®¿é—®å€¼
embed_dim = config.get('embed_dim', default_value)

# è½¬æ¢ä¸ºå­—å…¸
model_config = config.to_dict()
```

### æ¨¡å‹æ£€æŸ¥ç‚¹

æ‰€æœ‰æ¨¡å‹éƒ½æ”¯æŒæ£€æŸ¥ç‚¹ä¿å­˜å’ŒåŠ è½½ï¼š

```python
# ä¿å­˜æ£€æŸ¥ç‚¹
model.save_checkpoint('path/to/checkpoint.pth')

# åŠ è½½æ£€æŸ¥ç‚¹
model.load_checkpoint('path/to/checkpoint.pth')

# ä»…ä¿å­˜çŠ¶æ€å­—å…¸
torch.save(model.state_dict(), 'model_weights.pth')

# åŠ è½½çŠ¶æ€å­—å…¸
model.load_state_dict(torch.load('model_weights.pth'))
```

## è®­ç»ƒæ¨¡å‹

### ä½¿ç”¨è®­ç»ƒè„šæœ¬

æ¡†æ¶åŒ…å«ä¸€ä¸ªå…¨é¢çš„è®­ç»ƒè„šæœ¬ï¼š

```bash
# åŸºç¡€è®­ç»ƒ
python train.py --config configs/mae_config.yaml --output_dir outputs/mae_experiment

# ä½¿ç”¨è‡ªå®šä¹‰å‚æ•°çš„é«˜çº§è®­ç»ƒ
python train.py \
    --config configs/bert_config.yaml \
    --output_dir outputs/bert_experiment \
    --batch_size 32 \
    --learning_rate 1e-4 \
    --epochs 100 \
    --device cuda \
    --save_every 10
```

### è‡ªå®šä¹‰è®­ç»ƒå¾ªç¯

è¦è·å¾—æ›´å¤šæ§åˆ¶ï¼Œå®ç°è‡ªå·±çš„è®­ç»ƒå¾ªç¯ï¼š

```python
import torch
import torch.nn as nn
from torch.optim import AdamW
from models import MAE
from utils import Config

# è®¾ç½®
config = Config.from_file('configs/mae_config.yaml')
model = MAE(config.to_dict())
optimizer = AdamW(model.parameters(), lr=1e-4)
criterion = nn.MSELoss()

# è®­ç»ƒå¾ªç¯
model.train()
for epoch in range(num_epochs):
    for batch_idx, (data, _) in enumerate(dataloader):
        optimizer.zero_grad()
        
        # å‰å‘ä¼ æ’­
        outputs = model(data)
        loss = outputs['loss']
        
        # åå‘ä¼ æ’­
        loss.backward()
        optimizer.step()
        
        if batch_idx % 100 == 0:
            print(f'è½®æ¬¡ {epoch}, æ‰¹æ¬¡ {batch_idx}, æŸå¤±: {loss.item():.6f}')
    
    # ä¿å­˜æ£€æŸ¥ç‚¹
    if epoch % 10 == 0:
        model.save_checkpoint(f'checkpoint_epoch_{epoch}.pth')
```

## é«˜çº§ç”¨æ³•

### å‚æ•°å†»ç»“

æ§åˆ¶æ¨¡å‹çš„å“ªäº›éƒ¨åˆ†éœ€è¦è®­ç»ƒï¼š

```python
# å†»ç»“ç¼–ç å™¨ï¼Œä»…è®­ç»ƒè§£ç å™¨
model.freeze_encoder()

# å†»ç»“æ‰€æœ‰å‚æ•°ï¼Œé™¤äº†åˆ†ç±»å¤´
model.freeze_all()
model.unfreeze_classifier()

# è‡ªå®šä¹‰å†»ç»“
for name, param in model.named_parameters():
    if 'encoder' in name:
        param.requires_grad = False
```

### æ¨¡å‹æ£€æŸ¥

è·å–æ¨¡å‹çš„è¯¦ç»†ä¿¡æ¯ï¼š

```python
# æ¨¡å‹æ‘˜è¦
model.summary()

# å‚æ•°è®¡æ•°
total_params = model.count_parameters()
trainable_params = model.count_parameters(only_trainable=True)

# å±‚ä¿¡æ¯
for name, module in model.named_modules():
    print(f"{name}: {module}")

# å‚æ•°ä¿¡æ¯
for name, param in model.named_parameters():
    print(f"{name}: {param.shape}, requires_grad: {param.requires_grad}")
```

### å¤šGPUè®­ç»ƒ

ä½¿ç”¨DataParallelæˆ–DistributedDataParallelï¼š

```python
import torch.nn as nn

# DataParallelï¼ˆæ›´ç®€å•ä½†æ•ˆç‡è¾ƒä½ï¼‰
if torch.cuda.device_count() > 1:
    model = nn.DataParallel(model)
model = model.cuda()

# DistributedDataParallelï¼ˆæ¨èç”¨äºå¤šGPUï¼‰
# è¯¦ç»†è®¾ç½®è¯·å‚è§PyTorch DDPæ–‡æ¡£
```

## æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

1. **CUDAå†…å­˜ä¸è¶³ï¼š**
   - å‡å°‘æ‰¹æ¬¡å¤§å°
   - ä½¿ç”¨æ¢¯åº¦ç´¯ç§¯
   - å¯ç”¨æ··åˆç²¾åº¦è®­ç»ƒ

2. **æ¨¡å‹ä¸å­¦ä¹ ï¼š**
   - æ£€æŸ¥å­¦ä¹ ç‡ï¼ˆå°è¯•1e-3ã€1e-4ã€1e-5ï¼‰
   - éªŒè¯æ•°æ®é¢„å¤„ç†
   - æ£€æŸ¥æŸå¤±å‡½æ•°å’ŒæŒ‡æ ‡

3. **å¯¼å…¥é”™è¯¯ï¼š**
   - ç¡®ä¿æ‰€æœ‰ä¾èµ–éƒ½å·²å®‰è£…
   - æ£€æŸ¥Pythonè·¯å¾„å’ŒåŒ…å®‰è£…

4. **é…ç½®é”™è¯¯ï¼š**
   - éªŒè¯YAMLè¯­æ³•
   - æ£€æŸ¥å‚æ•°åç§°å’Œå€¼
   - å¦‚æœå¯ç”¨ï¼Œä½¿ç”¨Config.validate()

### æ€§èƒ½ä¼˜åŒ–

1. **å†…å­˜ä¼˜åŒ–ï¼š**
   ```python
   # å¯ç”¨æ··åˆç²¾åº¦
   from torch.cuda.amp import autocast, GradScaler
   
   scaler = GradScaler()
   model.train()
   
   for data in dataloader:
       optimizer.zero_grad()
       with autocast():
           outputs = model(data)
           loss = outputs['loss']
       
       scaler.scale(loss).backward()
       scaler.step(optimizer)
       scaler.update()
   ```

2. **æ¢¯åº¦ç´¯ç§¯ï¼š**
   ```python
   accumulation_steps = 4
   
   for i, (data, _) in enumerate(dataloader):
       outputs = model(data)
       loss = outputs['loss'] / accumulation_steps
       loss.backward()
       
       if (i + 1) % accumulation_steps == 0:
           optimizer.step()
           optimizer.zero_grad()
   ```

### è·å–å¸®åŠ©

1. æŸ¥çœ‹`docs/models/`ä¸­çš„æ¨¡å‹ç‰¹å®šæ–‡æ¡£
2. æŸ¥çœ‹`examples/`ä¸­çš„ç¤ºä¾‹è„šæœ¬
3. åœ¨GitHubä¸Šåˆ›å»ºIssueï¼ŒåŒ…å«ï¼š
   - å®Œæ•´çš„é”™è¯¯ä¿¡æ¯
   - èƒ½é‡ç°é—®é¢˜çš„ä»£ç ç‰‡æ®µ
   - ç¯å¢ƒè¯¦æƒ…ï¼ˆPythonç‰ˆæœ¬ã€PyTorchç‰ˆæœ¬ç­‰ï¼‰

## ä¸‹ä¸€æ­¥

- é˜…è¯»`docs/models/`ä¸­çš„å„ä¸ªæ¨¡å‹æŒ‡å—
- æ¢ç´¢`examples/`ä¸­çš„ç¤ºä¾‹è„šæœ¬
- å°è¯•åœ¨è‡ªå·±çš„æ•°æ®ä¸Šè®­ç»ƒ
- è¯•éªŒä¸åŒçš„é…ç½®
- Contribute improvements back to the project!