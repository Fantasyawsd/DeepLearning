# DeepLearning Models Framework | æ·±åº¦å­¦ä¹ æ¨¡å‹æ¡†æ¶

è¿™æ˜¯ä¸€ä¸ªå…¨é¢çš„æ·±åº¦å­¦ä¹ æ¨¡å‹æ¡†æ¶ï¼ŒåŒ…å«è®¡ç®—æœºè§†è§‰å’Œè‡ªç„¶è¯­è¨€å¤„ç†é¢†åŸŸçš„ç»å…¸æ¨¡å‹PyTorchå®ç°ï¼ŒæŒ‰ç…§é¢†åŸŸå’Œä»»åŠ¡åˆ†ç±»ç»„ç»‡ã€‚

*A comprehensive deep learning models framework with PyTorch implementations of classic models in computer vision and natural language processing, organized by domain and task.*

## ğŸ—ï¸ é¡¹ç›®ç»“æ„ | Project Structure

æœ¬é¡¹ç›®é‡‡ç”¨**é¢†åŸŸé©±åŠ¨**çš„ç»„ç»‡æ–¹å¼ï¼ŒæŒ‰ç…§åº”ç”¨é¢†åŸŸå’Œå…·ä½“ä»»åŠ¡åˆ†ç±»ï¼š

```
DeepLearning/
â”œâ”€â”€ computer_vision/           # è®¡ç®—æœºè§†è§‰
â”‚   â”œâ”€â”€ image_classification/  # å›¾åƒåˆ†ç±»
â”‚   â”‚   â”œâ”€â”€ cnn/              # CNNç³»åˆ—
â”‚   â”‚   â”‚   â”œâ”€â”€ lenet/        # LeNet-5 (1998) âœ…
â”‚   â”‚   â”‚   â”œâ”€â”€ alexnet/      # AlexNet (2012)
â”‚   â”‚   â”‚   â”œâ”€â”€ vgg/          # VGG (2014)
â”‚   â”‚   â”‚   â””â”€â”€ resnet/       # ResNetç³»åˆ— (2015) âœ…
â”‚   â”‚   â””â”€â”€ transformer/      # Transformerç³»åˆ—
â”‚   â”‚       â”œâ”€â”€ vit/          # Vision Transformer (2020) âœ…
â”‚   â”‚       â”œâ”€â”€ swin_transformer/ # Swin Transformer (2021)
â”‚   â”‚       â””â”€â”€ mae/          # Masked Autoencoder (2022) âœ…
â”‚   â””â”€â”€ object_detection/     # ç›®æ ‡æ£€æµ‹
â”‚       â”œâ”€â”€ rcnn_series/      # R-CNNç³»åˆ—
â”‚       â”‚   â”œâ”€â”€ rcnn/         # R-CNN (2014)
â”‚       â”‚   â”œâ”€â”€ fast_rcnn/    # Fast R-CNN (2015)
â”‚       â”‚   â”œâ”€â”€ faster_rcnn/  # Faster R-CNN (2015)
â”‚       â”‚   â””â”€â”€ mask_rcnn/    # Mask R-CNN (2017)
â”‚       â””â”€â”€ yolo_series/      # YOLOç³»åˆ—
â”‚           â”œâ”€â”€ yolov1/       # YOLOv1 (2016) âœ…
â”‚           â”œâ”€â”€ yolov3/       # YOLOv3 (2018)
â”‚           â”œâ”€â”€ yolov5/       # YOLOv5 (2020)
â”‚           â””â”€â”€ yolov8/       # YOLOv8 (2023)
â”œâ”€â”€ nlp/                      # è‡ªç„¶è¯­è¨€å¤„ç†
â”‚   â””â”€â”€ language_models/      # è¯­è¨€æ¨¡å‹
â”‚       â”œâ”€â”€ bert/             # BERT (2018)
â”‚       â”œâ”€â”€ gpt_series/       # GPTç³»åˆ—
â”‚       â”‚   â”œâ”€â”€ gpt/          # GPT-1 (2018) âœ…
â”‚       â”‚   â”œâ”€â”€ gpt2/         # GPT-2 (2019)
â”‚       â”‚   â””â”€â”€ gpt3/         # GPT-3 (2020)
â”‚       â””â”€â”€ llm/              # å¤§è¯­è¨€æ¨¡å‹
â”‚           â”œâ”€â”€ llama/        # LLaMA (2023)
â”‚           â””â”€â”€ chatglm/      # ChatGLM (2023)
â”œâ”€â”€ utils/                    # é€šç”¨å·¥å…·
â”œâ”€â”€ docs/                     # æ–‡æ¡£
â””â”€â”€ configs/                  # é…ç½®æ–‡ä»¶
```

## ğŸš€ æ ¸å¿ƒç‰¹æ€§ | Key Features

### ğŸ“¦ å®Œæ•´æ¨¡å‹åŒ…
æ¯ä¸ªæ¨¡å‹éƒ½åŒ…å«å®Œæ•´çš„ç»„ä»¶ï¼š
- **æ¨¡å‹å®šä¹‰** (`model.py`) - å®Œæ•´æ¶æ„å®ç°
- **æ•°æ®å¤„ç†** (`dataset.py`) - æ•°æ®åŠ è½½å’Œé¢„å¤„ç†
- **è®­ç»ƒè„šæœ¬** (`train.py`) - å®Œæ•´è®­ç»ƒæµç¨‹
- **æµ‹è¯•å·¥å…·** (`test.py`) - æ¨ç†å’Œè¯„ä¼°
- **é…ç½®æ–‡ä»¶** (`config.yaml`) - å¯è°ƒå‚æ•°é…ç½®
- **é¢„è®­ç»ƒé›†æˆ** (`load_pretrained.py`) - HuggingFaceæ¨¡å‹åŠ è½½
- **å®Œæ•´æ–‡æ¡£** (`README.md`) - ä½¿ç”¨æŒ‡å—å’Œç¤ºä¾‹

### ğŸ¯ ç»Ÿä¸€è®¾è®¡
- **ç»Ÿä¸€åŸºç±»**: æ‰€æœ‰æ¨¡å‹ç»§æ‰¿è‡ª `BaseModel`
- **ä¸€è‡´æ¥å£**: æ ‡å‡†åŒ–çš„è®­ç»ƒã€æ¨ç†å’Œé…ç½®æ¥å£
- **æ¨¡å—åŒ–è®¾è®¡**: å¯å¤ç”¨çš„ç»„ä»¶å’Œå·¥å…·å‡½æ•°

### ğŸŒ ä¸­æ–‡ä¼˜åŒ–
- **å®Œæ•´ä¸­æ–‡æ–‡æ¡£**: é’ˆå¯¹ä¸­æ–‡ç”¨æˆ·ä¼˜åŒ–çš„è¯´æ˜æ–‡æ¡£
- **ä¸­æ–‡æ³¨é‡Š**: è¯¦ç»†çš„ä»£ç ä¸­æ–‡æ³¨é‡Š
- **æœ¬åœŸåŒ–é…ç½®**: é€‚åˆä¸­æ–‡ç¯å¢ƒçš„é»˜è®¤è®¾ç½®

## ğŸ“– Documentation | æ–‡æ¡£

**ä¸»è¦æŒ‡å— | Main Guides:**
- **[ç”¨æˆ·æŒ‡å— | User Guide](docs/USER_GUIDE.md)** - å®Œæ•´æ¡†æ¶ä½¿ç”¨æ•™ç¨‹
- **[å…¥é—¨æ•™ç¨‹ | Tutorial](docs/TUTORIAL.md)** - é€æ­¥æ•™ç¨‹å’Œä»£ç ç¤ºä¾‹
- **[æ–‡æ¡£ç´¢å¼• | Documentation Index](docs/README.md)** - æ–‡æ¡£å¯¼èˆªä¸­å¿ƒ

**æ¨¡å‹æ–‡æ¡£ | Model Documentation:**
- **[MAE å®Œæ•´æŒ‡å—](computer_vision/image_classification/transformer/mae/README.md)** - è‡ªç›‘ç£è§†è§‰å­¦ä¹ 
- **[ViT æŒ‡å—](computer_vision/image_classification/transformer/vit/README.md)** - Vision Transformer
- **[ResNet æŒ‡å—](computer_vision/image_classification/cnn/resnet/README.md)** - æ®‹å·®ç½‘ç»œ
- **[YOLOv1 æŒ‡å—](computer_vision/object_detection/yolo_series/yolov1/README.md)** - å®æ—¶ç›®æ ‡æ£€æµ‹
- **[GPT æŒ‡å—](nlp/language_models/gpt_series/gpt/README.md)** - ç”Ÿæˆå¼è¯­è¨€æ¨¡å‹

## ğŸ† å·²å®ç°æ¨¡å‹ | Implemented Models

### ğŸ–¼ï¸ è®¡ç®—æœºè§†è§‰ | Computer Vision

#### å›¾åƒåˆ†ç±» | Image Classification

**CNN ç³»åˆ—:**
- âœ… **LeNet-5** (1998) - å·ç§¯ç¥ç»ç½‘ç»œå…ˆé©±ï¼Œæ‰‹å†™æ•°å­—è¯†åˆ«
- âœ… **ResNet** (2015) - æ®‹å·®ç½‘ç»œï¼Œè§£å†³æ·±åº¦ç½‘ç»œæ¢¯åº¦æ¶ˆå¤±é—®é¢˜
  - ResNet-18/34/50/101/152
  - Pre-activation ResNet

**Transformer ç³»åˆ—:**
- âœ… **ViT** (2020) - Vision Transformerï¼Œå°†Transformerå¼•å…¥è§†è§‰
  - ViT-Tiny/Small/Base/Large/Huge
  - DeiT (Data-efficient Image Transformers)
- âœ… **MAE** (2022) - æ©ç è‡ªç¼–ç å™¨ï¼Œè‡ªç›‘ç£è§†è§‰å­¦ä¹ 
  - å®Œæ•´ç¼–ç å™¨-è§£ç å™¨æ¶æ„
  - HuggingFaceé¢„è®­ç»ƒæ¨¡å‹é›†æˆ

#### ç›®æ ‡æ£€æµ‹ | Object Detection

**YOLO ç³»åˆ—:**
- âœ… **YOLOv1** (2016) - é¦–ä¸ªç«¯åˆ°ç«¯å®æ—¶ç›®æ ‡æ£€æµ‹ç³»ç»Ÿ
  - å®Œæ•´YOLOæ¶æ„å’ŒæŸå¤±å‡½æ•°
  - éæå¤§å€¼æŠ‘åˆ¶ (NMS)

### ğŸ’¬ è‡ªç„¶è¯­è¨€å¤„ç† | Natural Language Processing

**è¯­è¨€æ¨¡å‹ | Language Models:**
- âœ… **GPT** (2018) - ç”Ÿæˆå¼é¢„è®­ç»ƒTransformer
  - è‡ªå›å½’è¯­è¨€å»ºæ¨¡
  - æ–‡æœ¬ç”Ÿæˆå’Œåºåˆ—åˆ†ç±»
  - GPT-Small/Medium/Large/XLå˜ä½“

## ğŸš€ å¿«é€Ÿå¼€å§‹ | Quick Start

### 1. ç¯å¢ƒå®‰è£… | Installation

```bash
# å…‹éš†é¡¹ç›®
git clone https://github.com/Fantasyawsd/DeepLearning.git
cd DeepLearning

# å®‰è£…ä¾èµ–
pip install -r requirements.txt

# å®‰è£…åŒ…
pip install -e .
```

### 2. è¿è¡Œç¤ºä¾‹ | Run Examples

```bash
# MAEè‡ªç›‘ç£å­¦ä¹ ç¤ºä¾‹
cd computer_vision/image_classification/transformer/mae
python train.py --config config.yaml

# ViTå›¾åƒåˆ†ç±»ç¤ºä¾‹  
cd computer_vision/image_classification/transformer/vit
python train.py --config config.yaml

# GPTæ–‡æœ¬ç”Ÿæˆç¤ºä¾‹
cd nlp/language_models/gpt_series/gpt
python train.py --config config.yaml

# YOLOv1ç›®æ ‡æ£€æµ‹ç¤ºä¾‹
cd computer_vision/object_detection/yolo_series/yolov1
python train.py --config config.yaml
```

### 3. åŠ è½½é¢„è®­ç»ƒæ¨¡å‹ | Load Pretrained Models

```python
# MAEé¢„è®­ç»ƒæ¨¡å‹
from computer_vision.image_classification.transformer.mae.load_pretrained import load_pretrained_mae
model = load_pretrained_mae('mae-base')

# ViTé¢„è®­ç»ƒæ¨¡å‹
from computer_vision.image_classification.transformer.vit.load_pretrained import load_pretrained_vit
model = load_pretrained_vit('vit_base_patch16_224')
```

## ğŸ“Š æ¨¡å‹æ€§èƒ½å¯¹æ¯” | Model Performance

| æ¨¡å‹ | ä»»åŠ¡ | æ•°æ®é›† | å‚æ•°é‡ | æ€§èƒ½æŒ‡æ ‡ |
|------|------|--------|--------|---------|
| MAE-Base | è‡ªç›‘ç£å­¦ä¹  | ImageNet | 87M | 83.6% (å¾®è°ƒå) |
| ViT-Base | å›¾åƒåˆ†ç±» | ImageNet | 86M | 84.5% Top-1 |
| ResNet-50 | å›¾åƒåˆ†ç±» | ImageNet | 25M | 76.2% Top-1 |
| YOLOv1 | ç›®æ ‡æ£€æµ‹ | PASCAL VOC | 45M | 63.4 mAP |
| GPT-Small | è¯­è¨€æ¨¡å‹ | WebText | 117M | 18.3 PPL |

## ğŸ› ï¸ å¼€å‘è·¯çº¿å›¾ | Development Roadmap

### ğŸ¯ å³å°†å®Œæˆ | Coming Soon
- [ ] **AlexNet, VGG** - ç»å…¸CNNæ¶æ„
- [ ] **Faster R-CNN, Mask R-CNN** - ä¸¤é˜¶æ®µç›®æ ‡æ£€æµ‹
- [ ] **YOLOv3/v5/v8** - YOLOç³»åˆ—æ¼”è¿›
- [ ] **GPT-2/GPT-3** - GPTç³»åˆ—æ‰©å±•
- [ ] **LLaMA, ChatGLM** - ç°ä»£å¤§è¯­è¨€æ¨¡å‹

### ğŸ”® æœªæ¥è®¡åˆ’ | Future Plans
- [ ] **æ‰©æ•£æ¨¡å‹** (Diffusion Models)
- [ ] **å¤šæ¨¡æ€æ¨¡å‹** (CLIP, DALL-E)
- [ ] **å¼ºåŒ–å­¦ä¹ ** (DQN, PPO)
- [ ] **å›¾ç¥ç»ç½‘ç»œ** (GCN, GraphSAGE)

## ğŸ¤ è´¡çŒ®æŒ‡å— | Contributing

æ¬¢è¿è´¡çŒ®ä»£ç ï¼è¯·éµå¾ªä»¥ä¸‹æµç¨‹ï¼š

1. **Fork** é¡¹ç›®
2. åˆ›å»ºç‰¹æ€§åˆ†æ”¯: `git checkout -b feature/AmazingFeature`
3. æäº¤æ›´æ”¹: `git commit -m 'Add some AmazingFeature'`
4. æ¨é€åˆ†æ”¯: `git push origin feature/AmazingFeature`
5. æäº¤ **Pull Request**

### è´¡çŒ®è¦æ±‚ | Contribution Requirements
- ä»£ç ç¬¦åˆé¡¹ç›®è§„èŒƒ
- æ·»åŠ å®Œæ•´çš„æ–‡æ¡£å’Œç¤ºä¾‹
- åŒ…å«å•å…ƒæµ‹è¯•
- æä¾›ä¸­æ–‡æ–‡æ¡£

## ğŸ“„ è®¸å¯è¯ | License

æœ¬é¡¹ç›®é‡‡ç”¨ MIT è®¸å¯è¯ã€‚è¯¦è§ [LICENSE](LICENSE) æ–‡ä»¶ã€‚

## ğŸ™ è‡´è°¢ | Acknowledgments

æ„Ÿè°¢ä»¥ä¸‹è®ºæ–‡ä½œè€…å’Œå¼€æºé¡¹ç›®ï¼š
- MAE: He et al. (Meta AI)
- ViT: Dosovitskiy et al. (Google)
- ResNet: He et al. (Microsoft)
- YOLO: Redmon et al.
- GPT: Radford et al. (OpenAI)
- HuggingFace Transformers
- PyTorchå›¢é˜Ÿ

---

**â­ å¦‚æœè¿™ä¸ªé¡¹ç›®å¯¹ä½ æœ‰å¸®åŠ©ï¼Œè¯·ç»™ä¸ªæ˜Ÿæ ‡ï¼**

## å®‰è£…

1. å…‹éš†é¡¹ç›®
```bash
git clone https://github.com/Fantasyawsd/DeepLearning.git
cd DeepLearning
```

2. å®‰è£…ä¾èµ–
```bash
pip install -r requirements.txt
```

3. å®‰è£…åŒ…
```bash
pip install -e .
```

## ä½¿ç”¨æ–¹æ³•

### ğŸ“š è¯¦ç»†æ–‡æ¡£

æŸ¥çœ‹å®Œæ•´ä½¿ç”¨æŒ‡å—å’Œæ•™ç¨‹ï¼š
- **[ç”¨æˆ·æŒ‡å—](docs/USER_GUIDE.md)** - å®Œæ•´çš„æ¡†æ¶ä½¿ç”¨æ•™ç¨‹
- **[MAE å®Œæ•´æŒ‡å—](docs/models/MAE_GUIDE.md)** - MAEæ¨¡å‹è¯¦ç»†ä½¿ç”¨è¯´æ˜
- **[BERT å®Œæ•´æŒ‡å—](docs/models/BERT_GUIDE.md)** - BERTæ¨¡å‹è¯¦ç»†ä½¿ç”¨è¯´æ˜
- **[Swin Transformer å®Œæ•´æŒ‡å—](docs/models/SWIN_TRANSFORMER_GUIDE.md)** - Swin Transformeræ¨¡å‹è¯¦ç»†ä½¿ç”¨è¯´æ˜

### 1. å¿«é€Ÿä½“éªŒ

è¿è¡Œç¤ºä¾‹è„šæœ¬ï¼š
```bash
# MAEç¤ºä¾‹
python examples/mae_example.py

# BERTç¤ºä¾‹
python examples/bert_example.py

# Swin Transformerç¤ºä¾‹
python examples/swin_transformer_example.py
```

### 2. è®­ç»ƒæ¨¡å‹

ä½¿ç”¨é…ç½®æ–‡ä»¶è®­ç»ƒæ¨¡å‹ï¼š
```bash
# è®­ç»ƒMAE
python train.py --config configs/mae_config.yaml --output_dir outputs/mae

# è®­ç»ƒBERT
python train.py --config configs/bert_config.yaml --output_dir outputs/bert

# è®­ç»ƒSwin Transformer
python train.py --config configs/swin_config.yaml --output_dir outputs/swin
```

### 3. è‡ªå®šä¹‰ä½¿ç”¨

```python
from models import MAE, BERT, SwinTransformer
from utils import Config

# åŠ è½½é…ç½®
config = Config.from_file('configs/mae_config.yaml')

# åˆ›å»ºæ¨¡å‹
model = MAE(config.to_dict())

# æ¨¡å‹ä¿¡æ¯
model.summary()

# å‰å‘ä¼ æ’­
import torch
x = torch.randn(1, 3, 224, 224)
output = model(x)
```

## æ¨¡å‹ç‰¹æ€§

### é€šç”¨ç‰¹æ€§
- ç»Ÿä¸€çš„åŸºç¡€æ¨¡å‹ç±» (`BaseModel`)
- å®Œæ•´çš„æ£€æŸ¥ç‚¹ä¿å­˜/åŠ è½½æœºåˆ¶
- å‚æ•°å†»ç»“/è§£å†»åŠŸèƒ½
- æ¨¡å‹ä¿¡æ¯ç»Ÿè®¡

### MAEç‰¹æ€§
- å®Œæ•´çš„ç¼–ç å™¨-è§£ç å™¨æ¶æ„
- å¯é…ç½®çš„æ©ç æ¯”ä¾‹
- ä½ç½®ç¼–ç æ”¯æŒ
- é‡å»ºæŸå¤±è®¡ç®—

### BERTç‰¹æ€§
- å¤šç§ä»»åŠ¡æ”¯æŒï¼ˆMLMã€åˆ†ç±»ç­‰ï¼‰
- æ³¨æ„åŠ›æœºåˆ¶å¯è§†åŒ–
- çµæ´»çš„è¾“å…¥æ ¼å¼
- é¢„è®­ç»ƒæƒé‡å…¼å®¹

### Swin Transformerç‰¹æ€§
- åˆ†å±‚ç‰¹å¾æå–
- æ»‘åŠ¨çª—å£æ³¨æ„åŠ›
- ç›¸å¯¹ä½ç½®ç¼–ç 
- é«˜æ•ˆçš„è®¡ç®—å¤æ‚åº¦

## ä¾èµ–

- Python >= 3.8
- PyTorch >= 1.12.0
- transformers >= 4.20.0
- einops >= 0.4.1
- timm >= 0.6.7
- å…¶ä»–ä¾èµ–è§ `requirements.txt`

## è´¡çŒ®

æ¬¢è¿æäº¤PRå’ŒIssueï¼è¯·ç¡®ä¿ï¼š
1. ä»£ç ç¬¦åˆé¡¹ç›®è§„èŒƒ
2. æ·»åŠ å¿…è¦çš„æµ‹è¯•
3. æ›´æ–°ç›¸å…³æ–‡æ¡£

## è®¸å¯è¯

MIT License

## è‡´è°¢

æ„Ÿè°¢ä»¥ä¸‹è®ºæ–‡çš„ä½œè€…ï¼š
- MAE: He et al., "Masked Autoencoders Are Scalable Vision Learners"
- BERT: Devlin et al., "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"
- Swin Transformer: Liu et al., "Swin Transformer: Hierarchical Vision Transformer using Shifted Windows"
